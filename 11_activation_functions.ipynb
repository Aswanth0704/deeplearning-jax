{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the popular activation functions and their effects on the training. \n",
    "Its important to choose good activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/yx8gqbb90hbg0j25szlgylq00000gp/T/ipykernel_61305/846214971.py:14: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf')\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Any, Sequence\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "## import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## Jax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "## Flax\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "## optimization using optax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: TFRT_CPU_0\n"
     ]
    }
   ],
   "source": [
    "## dataset path: for storing all the downloaded datasets. This prevents duplicate downloads.\n",
    "DATASET_PATH = os.path.abspath(\"data/\")\n",
    "CHECKPOINT_PATH = os.path.abspath(\"saved_models/activation_functions/\")\n",
    "\n",
    "# check the device we will be using.\n",
    "print(f'device: {jax.devices()[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets download some of the pretrained models that will be used in this notebook\n",
    "import urllib.request # for downloading url based files.\n",
    "from urllib.error import HTTPError # Captures HTTP errors\n",
    "\n",
    "# github link to the saved models \n",
    "base_url = 'https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial3/'\n",
    "\n",
    "# files to download\n",
    "pretrained_files = [\n",
    "    \"FashionMNIST_elu.config\", \"FashionMNIST_elu.tar\",\n",
    "    \"FashionMNIST_leakyrelu.config\", \"FashionMNIST_leakyrelu.tar\",\n",
    "    \"FashionMNIST_relu.config\", \"FashionMNIST_relu.tar\",\n",
    "    \"FashionMNIST_sigmoid.config\", \"FashionMNIST_sigmoid.tar\",\n",
    "    \"FashionMNIST_swish.config\", \"FashionMNIST_swish.tar\",\n",
    "    \"FashionMNIST_tanh.config\", \"FashionMNIST_tanh.tar\"\n",
    "]\n",
    "\n",
    "# create checkpoint directory if it doesn't exist\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok= True)\n",
    "\n",
    "# for each file, check whether it already exists. if not, try downloading it.\n",
    "\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print('contact author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Activation functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement common activation functions present in jax.nn or flax.linen by ourselves for better understanding. <br>\n",
    "\n",
    "All the activation functions in nn.linen are in nn.Module so that they can be integrated into a neural network. <br>\n",
    "\n",
    "- sigmoid (nn.sigmoid)\n",
    "- tanh (nn.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "\n",
    "class Sigmoid(nn.Module):\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return 1/(1+ jnp.exp(-x))\n",
    "\n",
    "###################################\n",
    "\n",
    "class Tanh(nn.Module):\n",
    "    def __call__(self, x):\n",
    "        x_exp, neg_x_exp = jnp.exp(x), jnp.exp(-x)\n",
    "        return (x_exp-neg_x_exp)/(x_exp+ neg_x_exp)\n",
    "\n",
    "class ReLU(nn.Module):\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.maximum(x, 0)\n",
    "\n",
    "class LeakyReLU(nn.Module):\n",
    "\n",
    "    alpha: float = 0.1\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.where(x>0, x, self.alpha*x)\n",
    "\n",
    "class ELU(nn.Module):\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.where(x>0, x, jnp.exp(x)-1)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __call__(self, x):\n",
    "        return x*nn.sigmoid(x)\n",
    "\n",
    "act_fn_by_name = {\n",
    "    'sigmoid': Sigmoid,\n",
    "    'tanh': Tanh,\n",
    "    'relu': ReLU,\n",
    "    'leakyrelu': LeakyReLU,\n",
    "    'elu': ELU,\n",
    "    'swish': Swish,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
